---
sidebar:
  title: AI名词释义
  step: 1
  isTimeLine: true
title: AI名词释义
tags:
  - AI
  - 名词
categories:
  - Ai
---

# AI名词释义

本文用「通俗解释」和「深度视角」两种方式，梳理 Skill、MCP、RAG、Agent、Function Call、向量数据库等常见 AI 名词，方便查阅和入门。

---

## 第一部分：核心基础（模型的「大脑」与输入）

### 1. LLM 大语言模型

**通俗解释**：  
可以把 LLM 想象成公司里的一位「超级学霸实习生」。他读过海量书籍和资料，知识面很广，但一开始只是一张「懂得多」的白纸，不会主动干活，需要你给他清晰的指令，他才会按你的要求输出内容。你问什么、怎么问，决定了你能从他身上拿到什么结果。

**深度视角**：  
LLM（Large Language Model）是在大规模文本上预训练的自回归模型，通过预测下一个 token 学习语言的统计与推理模式。其能力来自海量参数与数据，本质是在高维表示空间中对「下一个词」的分布建模；与人类交互时，实际是在该空间里做条件采样。

---

### 2. Prompt 提示词

**通俗解释**：  
Prompt 就是你给这位「实习生」下的「工作指令」。指令越具体（比如「用表格形式总结」「不超过 200 字」「用通俗语言解释」），他交出来的活儿就越符合你的预期。写好 Prompt，相当于把需求说清楚，是用好大模型的第一步。

**深度视角**：  
Prompt 是配置化的输入，决定了模型在输入空间中的条件分布。好的 Prompt 实际上是在模型的隐空间（Latent Space）中进行搜索，定位到特定任务对应的激活路径，从而引导模型走向目标行为，而不是随机或无关输出。

---

### 3. Token

**通俗解释**：  
Token 可以理解成「计费与长度的最小单位」。模型不是按「字」或「词」来数，而是按 Token：中文可能一个字或几个字算一个 Token，英文一个词可能拆成多个 Token。你看到的「输入/输出长度限制」「按 Token 计费」，都是在这个单位上算的。

**深度视角**：  
Token 是分词（Tokenization）后的子词或词元，模型在词表上做 softmax 预测。Token 数直接对应序列长度，影响计算复杂度（如注意力机制的 O(n²)）和上下文窗口上限，是成本与能力权衡的核心维度。

---

### 4. Embedding 向量/嵌入

**通俗解释**：  
Embedding 就是把一段文字（或图片等）变成一长串数字（向量）。语义相近的内容，对应的数字串会「长得像」；语义差得远的，数字串就差别大。这样电脑就能用「算距离」的方式做「找相似内容」「做推荐」「做检索」，而不只是关键词匹配。

**深度视角**：  
Embedding 是将离散符号映射到连续向量空间的表示学习。好的嵌入空间里，几何距离（如余弦相似度、欧氏距离）对应语义相似度，为检索、聚类、下游分类等任务提供可计算的表征，是 RAG 与向量检索的数学基础。

---

## 第二部分：检索与知识增强

### 5. RAG 检索增强生成

**通俗解释**：  
RAG 相当于给「学霸实习生」配了一个「资料柜」：先把你自己的文档、知识库整理好存起来；用户提问时，先从柜子里找出和问题最相关的几份资料，再把「问题 + 这些资料」一起交给模型回答。这样模型既不会瞎编，又能用上你的私有知识，适合做客服、文档问答、内部知识库。

**深度视角**：  
RAG（Retrieval-Augmented Generation）将检索系统与生成模型结合：检索器（常基于向量相似度）从外部语料中取回相关片段，与 query 一起作为条件输入生成器，从而把「知识更新」和「幻觉控制」从模型参数中解耦，用外部记忆扩展模型能力边界。

---

### 6. 向量数据库

**通俗解释**：  
向量数据库是专门用来「按意思找东西」的仓库。你把文档、问题都变成一串数字（向量）存进去；查的时候也把问题变成向量，数据库帮你找出「数字最接近」的那几条。这样就能实现「语义搜索」：不一定要有关键词重合，意思相近就能被找出来。

**深度视角**：  
向量数据库针对高维向量的近似最近邻（ANN）检索做了存储与索引优化（如 HNSW、IVF），在可接受的召回率下大幅降低检索复杂度。它是 RAG、推荐、去重、语义搜索等场景的基础设施，将 Embedding 空间中的相似度查询工程化。

---

## 第三部分：能力扩展与工具调用

### 7. Agent 智能体

**通俗解释**：  
Agent 不像普通聊天那样「问一句答一句」，而是会自己拆任务、选工具、多步执行。比如你说「帮我查一下北京明天天气并总结成一段话」，他会先决定要「调天气 API」，拿到结果后再「总结」，相当于一个能自己规划、动手的「小助手」，直到把事办完或发现办不了。

**深度视角**：  
Agent 是在闭环中结合感知（当前状态）、规划（子目标与步骤）、执行（工具调用）与反馈（观察结果再决策）的自主系统。其核心是「决策 + 工具使用」：通过 LLM 做推理与规划，通过 Function Call / MCP 等接口与环境交互，实现多步、多工具的任务完成。

---

### 8. Function Call 函数调用

**通俗解释**：  
Function Call 就是让模型「说出」他想调用的能力：比如「请调用查天气函数，城市=北京」。你的程序解析这句话，真正去调 API、查数据库、发邮件，再把结果塞回给模型，模型根据结果继续回答。这样就把「会说话」和「会办事」连在一起，是插件、自动化、Agent 的底层能力。

**深度视角**：  
Function Call 是模型输出结构化调用规范（函数名 + 参数），由外部运行时执行并返回结果，再作为下一轮输入。它把自然语言与符号/API 能力对齐，使 LLM 从纯文本生成升级为「规划 + 工具调用」的决策节点，是 Agent 与工具链集成的标准方式。

---

### 9. MCP 模型上下文协议

**通俗解释**：  
MCP（Model Context Protocol）可以理解成「模型和外部世界对接」的统一接口。通过 MCP，模型可以安全、规范地使用数据库、文件、Figma、API 等能力，而不必把每种能力都写进 Prompt。就像给模型装了一套「标准插座」，插什么工具就有什么能力。

**深度视角**：  
MCP 定义了模型与外部工具/数据源之间的协议与数据格式，包括资源发现、调用方式与上下文注入。它把「上下文」和「工具」标准化，便于多模型、多工具组合与复用，降低幻觉与越权调用的风险，是构建可扩展 AI 应用的基础协议之一。

---

## 第四部分：配置与行为约束

### 10. Skill 技能

**通俗解释**：  
在 Cursor 等工具里，Skill 就是给 AI 写好的「使用说明书」或「固定技能包」。比如「如何写 commit message」「如何跑测试」「如何按项目规范改代码」。配置好之后，AI 在相关场景下会按这些说明执行，相当于把经验沉淀成可复用的规则，让 AI 行为更稳定、更符合你的习惯。

**深度视角**：  
Skill 是预定义的、可被模型加载的指令或规则集，通常以结构化文档（如 SKILL.md）存在。它在提示或上下文层面约束模型行为，相当于在隐空间中固定部分「任务路径」，使模型在特定领域或工作流中表现一致、可预期。

---

### 11. 幻觉（Hallucination）

**通俗解释**：  
幻觉就是模型「一本正经地胡说」：答案看起来很像人写的、很顺，但事实错误、或和你的文档不符。比如编造不存在的日期、书名、数据。RAG 通过「先查资料再回答」可以明显减轻幻觉；好的 Prompt 和约束也能减少瞎编。

**深度视角**：  
幻觉源于模型在未观测到真实依据时仍高置信度生成流畅文本，是自回归生成与训练数据偏差的固有现象。缓解手段包括：检索增强（注入真实依据）、约束解码（禁止或惩罚不合理 token）、引用与溯源（要求模型标注依据来源），以及系统层的 fact-check 与人工校验。

---

## 附录：名词速览表

| 名词 | 通俗理解 | 常见用途 |
|------|----------|----------|
| **LLM** | 大语言模型，能读能写的「学霸」 | 对话、写作、翻译、代码、推理 |
| **Prompt** | 给模型的指令/问题 | 控制输出风格、格式、领域 |
| **Token** | 文本的计费与长度单位 | 算价格、算上下文长度 |
| **Embedding** | 把文字变成「数字串」表示意思 | 相似度、检索、推荐 |
| **RAG** | 先查资料再让模型答 | 知识库问答、客服、文档助手 |
| **向量数据库** | 按「意思相近」存和查 | 语义搜索、RAG 检索 |
| **Agent** | 会自己规划、用工具的 AI | 自动化任务、多步操作 |
| **Function Call** | 模型说出要调的函数和参数 | 查 API、写库、发邮件等 |
| **MCP** | 模型和外部工具的统一接口 | 扩展模型能力、多工具编排 |
| **Skill** | 给 AI 的固定技能/规则配置 | 统一行为、规范、工作流 |
| **幻觉** | 模型编造看似正确但错误的内容 | 需用 RAG、约束、校验来减轻 |

---

以上内容覆盖了日常接触 AI 应用与开发时最常见的一批名词；理解它们有助于阅读文档、做技术选型和与团队沟通。若你有特别想展开的概念，可以在此基础上单独成篇。

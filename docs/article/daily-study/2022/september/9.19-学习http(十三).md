# 9.19-学习http(十三)

## **HTTPS是什么? SSL/TLS又是什么?**

### **为什么要有HTTPS?**

简单的回答是**因为 HTTP 不安全**。

由于 HTTP 天生明文的特点，整个传输过程完全透明，任何人都能够在链路中截获、 修改或者伪造请求 / 响应报文，数据不具有可信性。

### **什么是安全?**

既然 HTTP不安全，那什么样的通信过程才是安全的呢? 通常认为，如果通信过程具备了四个特性，就可以认为是安全的，这四个特性是:

- 机密性
- 完整性
- 身份认证
- 不可否认

**机密性**(Secrecy/Confidentiality)是指对数据的保密，只能由可信的人访问，对其他人是不可见的秘密，简单来说就是不能让不相关的人看到不该看的东西。

**完整性**(Integrity，也叫一致性)是指数据在传输过程中没有被窜改，不多也不少，完完整整地保持着原状。

**身份认证**(Authentication)是指确认对方的真实身份，也就是证明你真的是你，保证消息只能发送给可信的人。

第四个特性是**不可否认**(Non-repudiation/Undeniable)，也叫不可抵赖，意思是不能否认已经发生过的行为，不能说话不算数耍赖皮。

使用前三个特性，可以解决安全通信的大部分问题，但如果缺了不可否认，那通信的事务真实性就得不到保证，有可能出现老赖。

所以，只有同时具备了机密性、完整性、身份认证、不可否认这四个特性，通信双方的利益才能有保障，才能算得上是真正的安全。

### **什么是HTTPS?**

HTTPS 其实是一个非常简单的协议，RFC 文档很小，只有短短的 7 页，里面规定了**新的协议名https，默认端口号 443**，至于其他的什么请求 - 应答模式、报文结构、请求方法、URI、头字段、连接管理等等都完全沿用 HTTP，没有任何新的东西。

HTTPS 把 HTTP 下层的传输协议由 TCP/IP 换成了 SSL/TLS，由**HTTP over TCP/IP**变成了**HTTP over SSL/TLS**，让 HTTP 运行在了安全的 SSL/TLS 协议上，收发报文不再使用 Socket API， 而是调用专门的安全接口。

<img src="./assets/image-20220919145943462.png" alt="image-20220919145943462" style="zoom:50%;" />



所以说，HTTPS 本身并没有什么惊世骇俗的本事，全是靠着后面的 SSL/TLS撑腰。只要学会了 SSL/TLS，HTTPS 自然就手到擒来。

### **SSL/TLS**

SSL 即安全套接层(Secure Sockets Layer)，在 OSI 模型中处于第 5 层(会话层)，由网景公司于 1994 年发明，有 v2 和 v3 两个版本，而 v1 因为有严重的缺陷从未公开过。

SSL 发展到 v3 时已经证明了它自身是一个非常好的安全通信协议，于是互联网工程组 IETF `在 1999 年`把它改名为 TLS(传输层安全，Transport Layer Security)，正式标准化，版本号从 1.0 重新算起，所以` TLS1.0 实际上就是 SSLv3.1`。

到今天 TLS 已经发展出了三个版本，分别是 2006 年的 1.1、2008 年的 1.2 和去年 (2018)的 1.3，每个新版本都紧跟密码学的发展和互联网的现状，持续强化安全和性 能，已经成为了信息安全领域中的权威标准。

目前应用的`最广泛的 TLS 是 1.2`，而之前的协议(TLS1.1/1.0、SSLv3/v2)都已经被认为是不安全的，各大浏览器即将在 2020 年左右停止支持，所以接下来的讲解都针对的是 TLS1.2。

TLS 由记录协议、握手协议、警告协议、变更密码规范协议、扩展协议等几个子协议组成， 综合使用了对称加密、非对称加密、身份认证等许多密码学前沿技术。

### **OpenSSL**

说到 TLS，就不能不谈到 OpenSSL，它是一个著名的开源密码学程序库和工具包，几乎支持所有公开的加密算法和协议，已经成为了事实上的标准，许多应用软件都会使用它作为底层库来实现 TLS 功能，包括常用的 Web 服务器 Apache、Nginx 等。

OpenSSL 是从另一个开源库 SSLeay 发展出来的，曾经考虑命名为OpenTLS，但当时 (1998 年)TLS 还未正式确立，而 SSL 早已广为人知，所以最终使用了OpenSSL的名字。

### **小结**

- 因为 HTTP 是明文传输，所以不安全，容易被黑客窃听或窜改
-  通信安全必须同时`具备机密性、完整性，身份认证和不可否认这四个特性`
-  HTTPS 的语法、语义仍然是 HTTP，但`把下层的协议由 TCP/IP 换成了 SSL/TLS`
- SSL/TLS 是信息安全领域中的权威标准，采用多种先进的加密技术保证通信安全
- OpenSSL 是著名的开源密码学工具包，是 SSL/TLS 的具体实现



## **对称加密与非对称加密**

在上面, 我们初步学习了 HTTPS，知道 HTTPS 的安全性是由 TLS 来保证的。

你一定很好奇，它是怎么为 HTTP 增加了机密性、完整性，身份认证和不可否认等特性的呢?

先说说机密性。它是信息安全的基础，缺乏机密性 TLS 就会成为无水之源、无根之木。

实现机密性最常用的手段是**加密**(encrypt)，就是把消息用某种方式转换成谁也看不懂的乱码，只有掌握特殊钥匙的人才能再转换出原始文本。

这里的钥匙就叫做**密钥**(key)，加密前的消息叫**明文**(plain text/clear text)，加密后的乱码叫**密文**(cipher text)，使用密钥还原明文的过程叫**解 密**(decrypt)，是加密的反操作，加密解密的操作过程就是**加密算法**。

所有的加密算法都是公开的，任何人都可以去分析研究，而算法使用的密钥则必须保密。那么，这个关键的密钥又是什么呢?

由于 HTTPS、TLS 都运行在计算机上，所以密钥就是一长串的数字，但约定俗成的度 量单位是位(bit)，而不是字节(byte)。比如，说密钥长度是 128，就是 16 字节的二进制串，密钥长度 1024，就是 128 字节的二进制串。

按照密钥的使用方式，加密可以分为两大类:**对称加密和非对称加密**。

### **对称加密**

对称加密很好理解，就是指`加密和解密时使用的密钥`都是同一个，是对称的。只要保证了密钥的安全，那整个通信过程就可以说具有了机密性。

举个例子，你想要登录某网站，只要事先和它约定好使用一个对称密码，通信过程中传输的全是用密钥加密后的密文，只有你和网站才能解密。黑客即使能够窃听，看到的也只是乱码，因为没有密钥无法解出明文，所以就实现了机密性。

<img src="./assets/image-20220919181001505.png" alt="image-20220919181001505" style="zoom:50%;" />

TLS 里有非常多的对称加密算法可供选择，比如 RC4、DES、3DES、AES、ChaCha20 等，但前三种算法都被认为是不安全的，通常都禁止使用，目前常用的只有 AES 和 ChaCha20。

AES 的意思是高级加密标准(Advanced Encryption Standard)，密钥长度可以是 128、192 或 256。它是 DES 算法的替代者，安全强度很高，性能也很好，而且有的硬件还会做特殊优化，所以非常流行，是应用最广泛的对称加密算法。

ChaCha20 是 Google 设计的另一种加密算法，密钥长度固定为 256 位，纯软件运行性能 要超过 AES，曾经在移动客户端上比较流行，但 ARMv8 之后也加入了 AES 硬件优化，所 以现在不再具有明显的优势，但仍然算得上是一个不错算法。

### **非对称加密**

对称加密看上去好像完美地实现了机密性，但其中有一个很大的问题:如何把密钥安全地传递给对方，术语叫**密钥交换**。

因为在对称加密算法中只要持有密钥就可以解密。如果你和网站约定的密钥在传递途中被黑客窃取，那他就可以在之后随意解密收发的数据，通信过程也就没有机密性可言了。

这个问题该怎么解决呢?

你或许会说:把密钥再加密一下发过去就好了，但传输加密密钥的密钥又成了新问题。这就像是鸡生蛋、蛋生鸡，可以无限递归下去。只用对称加密算法，是绝对无法解决密钥交换的问题的。所以，就出现了非对称加密(也叫公钥加密算法)。

它有两个密钥，一个叫**公钥**(public key)，一个叫**私钥**(private key)。两个密钥是不同的，不对称，`公钥可以公开给任何人使用，而私钥必须严格保密`。

公钥和私钥有个特别的**单向**性，虽然都可以用来加密解密，但公钥加密后只能用私钥解 密，反过来，私钥加密后也只能用公钥解密。

`非对称加密可以解决密钥交换的问题`。网站秘密保管私钥，在网上任意分发公钥，你想要登录网站只要用公钥加密就行了，密文只能由私钥持有者才能解密。而黑客因为没有私钥，所以就无法破解密文。

<img src="./assets/image-20220919181330179.png" alt="image-20220919181330179" style="zoom:50%;" />

非对称加密算法的设计要比对称算法难得多，在 TLS 里只有很少的几种，比如 DH、 DSA、RSA、ECC 等。

RSA 可能是其中最著名的一个，几乎可以说是非对称加密的代名词，它的安全性基于**整数分解**的数学难题，使用两个超大素数的乘积作为生成密钥的材料，想要从公钥推算出私 钥是非常困难的。

10 年前 RSA 密钥的推荐长度是 1024，但随着计算机运算能力的提高，现在 1024 已经不安全，普遍认为至少要 2048 位。

ECC(Elliptic Curve Cryptography)是非对称加密里的后起之秀，它基于**椭圆曲线离散对数**的数学难题，使用特定的曲线方程和基点生成公钥和私钥，子算法 ECDHE 用于 密钥交换，ECDSA 用于数字签名。

目前比较常用的两个曲线是 P-256(secp256r1，在 OpenSSL 称为 prime256v1)和 x25519。P-256 是 NIST(美国国家标准技术研究所)和 NSA(美国国家安全局)推荐使 用的曲线，而 x25519 被认为是最安全、最快速的曲线。

比起 RSA，ECC 在安全强度和性能上都有明显的优势。160 位的 ECC 相当于 1024 位的 RSA，而 224 位的 ECC 则相当于 2048 位的 RSA。因为密钥短，所以相应的计算量、消耗 的内存和带宽也就少，加密解密的性能就上去了，对于现在的移动互联网非常有吸引力。

### **混合加密**

看到这里，你是不是认为可以抛弃对称加密，只用非对称加密来实现机密性呢?

很遗憾，虽然非对称加密没有密钥交换的问题，但因为它们都是基于复杂的数学难题， 运算速度很慢，即使是 ECC 也要比 AES 差上好几个数量级。如果仅用非对称加密，虽然保证了安全，但通信速度有如乌龟、蜗牛，实用性就变成了零。

那么，是不是能够把对称加密和非对称加密结合起来呢，两者互相取长补短，即能高效地加密解密，又能安全地密钥交换。

这就是现在 TLS 里使用的**混合加密**方式，其实说穿了也很简单:

- 在通信刚开始的时候使用非对称算法，比如 RSA、ECDHE，首先解决密钥交换的问题。

- 然后用随机数产生对称算法使用的**会话密钥**(session key)，再用公钥加密。因为会话密钥很短，通常只有 16 字节或 32 字节，所以慢一点也无所谓。
- 对方拿到密文后用私钥解密，取出会话密钥。这样，双方就实现了对称密钥的安全交换，后续就不再使用非对称加密，全都使用对称加密。

<img src="./assets/image-20220919181812092.png" alt="image-20220919181812092" style="zoom:50%;" />

这样混合加密就解决了对称加密算法的密钥交换问题，而且安全和性能兼顾，完美地实现了机密性。

### **小结**

- 加密算法的核心思想是把一个小秘密(密钥)转化为一个大秘密(密文消息)，守住了小秘密，也就守住了大秘密
- `对称加密只使用一个密钥`，运算速度快，密钥必须保密，`无法做到安全的密钥交换`，常用的有 AES 和 ChaCha20
- `非对称加密使用两个密钥:公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢，常用的有 RSA 和 ECC`
- 把对称加密和非对称加密结合起来就得到了又好又快的混合加密，也就是` TLS 里使用的加密方式(混合加密)`

## **数字签名与证书**

在上面, 我们学习了对称加密和非对称加密，以及两者结合起来的混合加密，实现了机密性。

但仅有机密性，离安全还差的很远。

黑客虽然拿不到会话密钥，无法破解密文，但可以通过窃听收集到足够多的密文，再尝试着修改、重组后发给网站。因为没有完整性保证，服务器只能照单全收，然后他就可以通过服务器的响应获取进一步的线索，最终就会破解出明文。

另外，黑客也可以伪造身份发布公钥。如果你拿到了假的公钥，混合加密就完全失效了。你以为自己是在和某宝通信，实际上网线的另一端却是黑客，银行卡号、密码等敏感信息就在安全的通信过程中被窃取了。

所以，在机密性的基础上还必须加上完整性、身份认证等特性，才能实现真正的安全。

### **摘要算法**

实现完整性的手段主要是**摘要算法**(Digest Algorithm)，也就是常说的散列函数、哈希函数(Hash Function)。

你可以把摘要算法近似地理解成一种特殊的压缩算法，它能够把任意长度的数据压缩成固定长度、而且独一无二的摘要字符串，就好像是给这段数据生成了一个数字指纹。

换一个角度，也可以把摘要算法理解成特殊的单向加密算法，它只有算法，没有密钥，加密后的数据无法解密，不能从摘要逆推出原文。

摘要算法实际上是把数据从一个大空间映射到了小空间，所以就存在冲突(collision，也叫碰撞)的可能性，就如同现实中的指纹一样，可能会有两份不同的原文对应相同的摘要。好的摘要算法必须能够抵抗冲突，让这种可能性尽量地小。

因为摘要算法对输入具有单向性和雪崩效应，输入的微小不同会导致输出的剧烈变化，所以也被 TLS 用来生成伪随机数(PRF，pseudo random function)。

你一定在日常工作中听过、或者用过 MD5(Message-Digest 5)、SHA-1(Secure Hash Algorithm 1)，它们就是最常用的两个摘要算法，能够生成 16 字节和 20 字节长度 的数字摘要。但这两个算法的安全强度比较低，不够安全，在 TLS 里已经被禁止使用了。

目前 TLS 推荐使用的是 SHA-1 的后继者:SHA-2。

SHA-2 实际上是一系列摘要算法的统称，总共有 6 种，常用的有 SHA224、SHA256、 SHA384，分别能够生成 28 字节、32 字节、48 字节的摘要。

### **完整性**

摘要算法保证了数字摘要和原文是完全等价的。所以，我们只要在原文后附上它的摘要，就能够保证数据的完整性。

比如，你发了条消息:转账 1000 元，然后再加上一个 SHA-2 的摘要。网站收到后也计算一下消息的摘要，把这两份指纹做个对比，如果一致，就说明消息是完整可信的， 没有被修改。

如果黑客在中间哪怕改动了一个标点符号，摘要也会完全不同，网站计算比对就会发现消息被窜改，是不可信的。不过摘要算法不具有机密性，如果明文传输，那么黑客可以修改消息后把摘要也一起改了，网站还是鉴别不出完整性。

所以，真正的完整性必须要建立在机密性之上，在混合加密系统里用会话密钥加密消息和摘要，这样黑客无法得知明文，也就没有办法动手脚了。

这有个术语，叫哈希消息认证码(HMAC)。

<img src="./assets/image-20220919183424984.png" alt="image-20220919183424984" style="zoom:50%;" />



### **数字签名**

加密算法结合摘要算法，我们的通信过程可以说是比较安全了。但这里还有漏洞，就是通信的两个端点(endpoint)。

就像一开始所说的，黑客可以伪装成网站来窃取信息。而反过来，他也可以伪装成你，向网站发送支付、转账等消息，网站没有办法确认你的身份，钱可能就这么被偷走了。

现实生活中，解决身份认证的手段是签名和印章，只要在纸上写下签名或者盖个章，就能够证明这份文件确实是由本人而不是其他人发出的。

你回想一下之前的课程，在 TLS 里有什么东西和现实中的签名、印章很像，只能由本人持有，而其他任何人都不会有呢?只要用这个东西，就能够在数字世界里证明你的身份。

没错，这个东西就是非对称加密里的**私钥**，使用私钥再加上摘要算法，就能够实现**数字签名**，同时实现身份认证和不可否认。

`数字签名的原理其实很简单，就是把公钥私钥的用法反过来，之前是公钥加密、私钥解密，现在是私钥加密、公钥解密`。

但又因为非对称加密效率太低，所以私钥只加密原文的摘要，这样运算量就小的多，而且得到的数字签名也很小，方便保管和传输。

签名和公钥一样完全公开，任何人都可以获取。但这个签名只有用私钥对应的公钥才能解开，拿到摘要后，再比对原文验证完整性，就可以像签署文件一样证明消息确实是你发的。

<img src="./assets/image-20220919183627274.png" alt="image-20220919183627274" style="zoom:50%;" />

刚才的这两个行为也有专用术语，叫做**签名**和**验签**。

只要你和网站互相交换公钥，就可以用签名和验签来确认消息的真实性，因为私钥

保密，黑客不能伪造签名，就能够保证通信双方的身份。

比如，你用自己的私钥签名一个消息我是小明。网站收到后用你的公钥验签，确认身份没问题，于是也用它的私钥签名消息我是某宝。你收到后再用它的公钥验一下，也没问题，这样你和网站就都知道对方不是假冒的，后面就可以用混合加密进行安全通信了。

### **数字证书和 CA**

到现在，综合使用对称加密、非对称加密和摘要算法，我们已经实现了安全的四大特性，是不是已经完美了呢?

不是的，这里还有一个**公钥的信任**问题。因为谁都可以发布公钥，我们还缺少防止黑客伪造公钥的手段，也就是说，怎么来判断这个公钥就是你或者某宝的公钥呢?

真是按下葫芦又起了瓢，安全还真是个麻烦事啊，一环套一环的。

我们可以用类似密钥交换的方法来解决公钥认证问题，用别的私钥来给公钥签名，显然，这又会陷入无穷递归。

但这次实在是没招了，要终结这个死循环，就必须引入外力，找一个公认的可信第三方，让它作为信任的起点，递归的终点，构建起公钥的信任链。

这个第三方就是我们常说的**CA**(Certificate Authority，证书认证机构)。它就像网络世界里的公安局、教育部、公证中心，具有极高的可信度，由它来给各个公钥签名，用自身的信誉来保证公钥无法伪造，是可信的。

CA 对公钥的签名认证也是有格式的，不是简单地把公钥绑定在持有者身份上就完事了，还 要包含序列号、用途、颁发者、有效时间等等，把这些打成一个包再签名，完整地证明公钥 关联的各种信息，形成**数字证书**(Certificate)。

知名的 CA 全世界就那么几家，比如 DigiCert、VeriSign、Entrust、Let’s Encrypt 等，它们签发的证书分 DV、OV、EV 三种，区别在于可信程度。

DV 是最低的，只是域名级别的可信，背后是谁不知道。EV 是最高的，经过了法律和审计的严格核查，可以证明网站拥有者的身份(在浏览器地址栏会显示出公司的名字，例如 Apple、GitHub 的网站)。

不过，CA 怎么证明自己呢?

这还是信任链的问题。小一点的 CA 可以让大 CA 签名认证，但链条的最后，也就是**Root CA**，就只能自己证明自己了，这个就叫**自签名证书**(Self-Signed Certificate)或者**根证书**(Root Certificate)。你必须相信，否则整个证书信任链就走不下去了。

<img src="./assets/image-20220919183924370.png" alt="image-20220919183924370" style="zoom:50%;" />

有了这个证书体系，操作系统和浏览器都内置了各大 CA 的根证书，上网的时候只要服务器发过来它的证书，就可以验证证书里的签名，顺着证书链(Certificate Chain)一层层地验证，直到找到根证书，就能够确定证书是可信的，从而里面的公钥也是可信的。

### **证书体系的弱点**

证书体系(PKI，Public Key Infrastructure)虽然是目前整个网络世界的安全基础设施， 但绝对的安全是不存在的，它也有弱点，还是关键的**信任**二字。

如果 CA 失误或者被欺骗，签发了错误的证书，虽然证书是真的，可它代表的网站却是假的。

还有一种更危险的情况，CA 被黑客攻陷，或者 CA 有恶意，因为它(即根证书)是信任的源头，整个信任链里的所有证书也就都不可信了。

这两种事情并不是耸人听闻，都曾经实际出现过。所以，需要再给证书体系打上一些补丁。

针对第一种，开发出了 CRL(证书吊销列表，Certificate revocation list)和 OCSP(在线证书状态协议，Online Certificate Status Protocol)，及时废止有问题的证书。

对于第二种，因为涉及的证书太多，就只能操作系统或者浏览器从根上下狠手了，撤销对 CA 的信任，列入黑名单，这样它颁发的所有证书就都会被认为是不安全的。

### **小结**

- 摘要算法用来实现完整性，能够为数据生成独一无二的指纹，常用的算法是 SHA- 2
- 数字签名是私钥对摘要的加密，可以由公钥解密后验证，实现身份认证和不可否认
- 公钥的分发需要使用数字证书，必须由 CA 的信任链来验证，否则就是不可信的
- 作为信任链的源头 CA 有时也会不可信，解决办法有 CRL、OCSP，还有终止信任

## 参考

[透视HTTP协议(罗剑锋)](https://time.geekbang.org/column/intro/100029001)